{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kmsaleh/Inheritance-in-ML-projects/blob/main/ML_inhritance_Extended.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CjJdqLAhF4j"
      },
      "source": [
        "**Define a BaseModel**<br>\n",
        "Letâ€™s code a base machine learning model class that is defined by some standard variable. This class then will have a method to load the data, one to train, another to evaluate, and one to preprocess the data. However, each specific model will preprocess the data differently, so the subclasses that will inherit the base model shall rewrite the preprocessing method.\n",
        "Be alert, the BaseMLModel itself inherit the ABC class. This is a way to tell Python that this class is an abstract class, and shall not be used, but it's only a template to build subclasses.\n",
        "\n",
        "The same is true for the preprocess_train_data which is marked a @abstactmethod. This means that subclasses must reimplement this method."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from abc import ABC, abstractmethod\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis  # extension no. 1  khaled\n",
        "from sklearn.datasets import load_iris\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "Pu1kcUd2Vbro"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BaseMLModel(ABC):\n",
        "    def __init__(self, test_size = 0.2, random_state = 42):\n",
        "        self.model = None   # this will be set in subclass\n",
        "        self.test_size = test_size\n",
        "        self.random_state = random_state\n",
        "        self.X_train = None\n",
        "        self.X_test = None\n",
        "        self.y_train = None\n",
        "        self.y_test = None\n",
        "\n",
        "    def load_data(self, X, y):\n",
        "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
        "            X,y,test_size = self.test_size,random_state = self.random_state\n",
        "        )\n",
        "\n",
        "    @abstractmethod\n",
        "    def preprocess_train_data(self):\n",
        "        # each method can define custom preprocessing for training data\n",
        "        pass\n",
        "\n",
        "    def train(self):\n",
        "        self.X_train, self.y_train = self.preprocess_train_data()\n",
        "        self.model.fit(self.X_train, self.y_train)\n",
        "\n",
        "    def evaluate(self):\n",
        "        self.X_test = self.preprocess_test_data()   #preprocess test data\n",
        "        predictions = self.model.predict(self.X_test)\n",
        "        return accuracy_score(self.y_test, predictions)\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "jVbbI5M9Vpqs"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7YjfKMchF4s"
      },
      "source": [
        "First, we can implement a LogisticRegressionModel. Which will have its own preprocessing algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ufNz5PofhF4t"
      },
      "outputs": [],
      "source": [
        "class LogisticRegressionModel(BaseMLModel):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__()\n",
        "        self.model = LogisticRegression(**kwargs)\n",
        "        self.mean = None\n",
        "        self.std = None\n",
        "\n",
        "    def preprocess_train_data(self):\n",
        "        # standardize features for Logistic Regression\n",
        "        self.mean = self.X_train.mean(axis = 0)\n",
        "        self.std = self.X_train.std(axis = 0)\n",
        "        X_train_scaled = (self.X_train - self.mean)/self.std\n",
        "        return X_train_scaled, self.y_train\n",
        "\n",
        "    def preprocess_test_data(self):\n",
        "        # Apply the same standardization to test data\n",
        "        if self.mean is None or self.std is None:\n",
        "            raise ValueError(\"Training data must be preprocessed before preprocessing test data.\")\n",
        "        X_test_scaled = (self.X_test - self.mean)/self.std\n",
        "        return X_test_scaled\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyv5yi7phF4u"
      },
      "source": [
        "Then we can define as many subclasses as we want. I define here one for a Random Forest."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1lGC3z8rhF4u"
      },
      "outputs": [],
      "source": [
        "class RandomForestModel(BaseMLModel):\n",
        "    def __init__(self, n_important_features=3, **kwargs):\n",
        "        super().__init__()\n",
        "        self.model = RandomForestClassifier(**kwargs)\n",
        "        self.n_important_features = n_important_features\n",
        "        self.selected_feayures_indices = None\n",
        "\n",
        "    def preprocess_train_data(self):\n",
        "        # select top 'n_important_features' features based on variance\n",
        "        feature_variances = np.var(self.X_train, axis=0)\n",
        "        self.selected_features_indices = np.argsort(feature_variances)[-self.n_important_features:]\n",
        "        X_train_selected = self.X_train[:, self.selected_features_indices]\n",
        "        return X_train_selected, self.y_train\n",
        "\n",
        "    def preprocess_test_data(self):\n",
        "        # Apply the same feature selection to the test data\n",
        "        if self.selected_features_indices is None:\n",
        "            raise ValueError(\"Training data must be preprocessed before preprocessing test data.\")\n",
        "        X_test_selected = self.X_test[:, self.selected_features_indices]\n",
        "        return X_test_selected"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHOBJCRhhF4v"
      },
      "source": [
        "**Extension to the code**<br> 1- <i>LinearDiscriminantAnalysis (LDA)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LDAModel(BaseMLModel):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__()\n",
        "        self.model = sklearn.discriminant_analysis.LinearDiscriminantAnalysis(**kwargs)\n",
        "        self.lda_extractor = None  # To reuse the same LDA object for training and testing\n",
        "\n",
        "    def preprocess_train_data(self):\n",
        "        n_classes = len(set(self.y_train))\n",
        "        self.lda_extractor = sklearn.discriminant_analysis.LinearDiscriminantAnalysis(\n",
        "            n_components=min(n_classes - 1, self.X_train.shape[1])\n",
        "        )\n",
        "        self.X_train = self.lda_extractor.fit_transform(self.X_train, self.y_train)\n",
        "        return self.X_train, self.y_train\n",
        "\n",
        "    def preprocess_test_data(self):\n",
        "        if self.lda_extractor is None:\n",
        "            raise ValueError(\"LDA extractor must be fitted before transforming test data.\")\n",
        "        self.X_test = self.lda_extractor.transform(self.X_test)\n",
        "        return self.X_test\n",
        "\n",
        "    def transform(self, X):\n",
        "        if self.lda_extractor is None:\n",
        "            raise ValueError(\"LDA extractor must be fitted before transforming data.\")\n",
        "        return self.lda_extractor.transform(X)\n",
        "\n",
        "    def train(self):\n",
        "        self.X_train, self.y_train = self.preprocess_train_data()\n",
        "        self.model.fit(self.X_train, self.y_train)\n",
        "\n",
        "    def evaluate(self):\n",
        "        self.X_test = self.preprocess_test_data()\n",
        "        predictions = self.model.predict(self.X_test)\n",
        "\n",
        "        print(\"Confusion Matrix:\")\n",
        "        print(confusion_matrix(self.y_test, predictions))\n",
        "\n",
        "        print(\"Classification Report:\")\n",
        "        print(classification_report(self.y_test, predictions, target_names=data.target_names))\n",
        "\n",
        "        return accuracy_score(self.y_test, predictions)\n",
        "\n"
      ],
      "metadata": {
        "id": "jzlLv69jWLOs"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oReRljvehF4v"
      },
      "source": [
        "Then we can use all of this in our main function:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Load the dataset\n",
        "    data = load_iris()\n",
        "    X,y = data.data , data.target\n",
        "\n",
        "    # Logistic Regression\n",
        "    log_reg_model = LogisticRegressionModel(max_iter = 200)\n",
        "    log_reg_model.load_data(X,y)\n",
        "    log_reg_model.train()\n",
        "    print(f\"Logistic Regression Accuracy: {log_reg_model.evaluate()}\")\n",
        "    print('=========================================================')\n",
        "\n",
        "    # Random Forest\n",
        "    rf_model = RandomForestModel(n_estimators = 100, n_important_features = 3)\n",
        "    rf_model.load_data(X,y)\n",
        "    rf_model.train()\n",
        "    print(f\"Random Forest Accuracy: {rf_model.evaluate()}\")\n",
        "    print('=========================================================')\n",
        "\n",
        "    # LDA Model\n",
        "    lda_model = LDAModel()\n",
        "    lda_model.load_data(X, y)\n",
        "    lda_model.train()\n",
        "    accuracy = lda_model.evaluate()\n",
        "    print(f\"LDA Model Accuracy: {accuracy}\")\n",
        "    print('=========================================================')\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56sZ2y3dWW9w",
        "outputId": "d605277b-b2d0-45d8-85e2-efe39fd98e7c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy: 1.0\n",
            "=========================================================\n",
            "Random Forest Accuracy: 1.0\n",
            "=========================================================\n",
            "Confusion Matrix:\n",
            "[[10  0  0]\n",
            " [ 0  9  0]\n",
            " [ 0  0 11]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        10\n",
            "  versicolor       1.00      1.00      1.00         9\n",
            "   virginica       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n",
            "LDA Model Accuracy: 1.0\n",
            "=========================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJye2MLahF4x"
      },
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}